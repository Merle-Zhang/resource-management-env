{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "jobs = np.array(\n",
    "    [[[[True,  True, False],\n",
    "        [True, False,  True],\n",
    "        [True, False,  True],\n",
    "        [False, False,  True],\n",
    "        [False,  True,  True]],\n",
    "\n",
    "      [[False, False,  True],\n",
    "        [True,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [False, False, False],\n",
    "        [False,  True, False]]],\n",
    "\n",
    "\n",
    "      [[[False, False,  True],\n",
    "        [False,  True, False],\n",
    "        [True,  True,  True],\n",
    "        [False, False,  True],\n",
    "        [False, False, False]],\n",
    "\n",
    "      [[False, False,  True],\n",
    "        [True, False, False],\n",
    "        [True, False,  True],\n",
    "        [True,  True, False],\n",
    "        [True, False, False]]],\n",
    "\n",
    "\n",
    "      [[[True, False, False],\n",
    "        [False, False,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True, False],\n",
    "        [False, False,  True]],\n",
    "\n",
    "      [[True,  True,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True,  True],\n",
    "        [False, False,  True],\n",
    "        [False, False, False]]],\n",
    "\n",
    "\n",
    "      [[[False, False,  True],\n",
    "        [True,  True, False],\n",
    "        [False,  True, False],\n",
    "        [False,  True,  True],\n",
    "        [True, False, False]],\n",
    "\n",
    "      [[False,  True, False],\n",
    "        [False,  True, False],\n",
    "        [True,  True, False],\n",
    "        [False, False, False],\n",
    "        [True, False,  True]]],\n",
    "\n",
    "\n",
    "      [[[True, False,  True],\n",
    "        [False,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [True, False, False],\n",
    "        [True, False,  True]],\n",
    "\n",
    "      [[True,  True, False],\n",
    "        [False,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True,  True]]]]\n",
    ")\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(121,)\n",
      "Action:\n",
      " 0\n",
      "Step:\n",
      " [1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000\n",
      " 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000\n",
      " 1000 1000    1    1    0    1    0    1    1    0    1    0    0    1\n",
      "    0    1    1    0    0    1    1    1    1    0    1    1    0    0\n",
      "    0    0    1    0    0    0    1    0    1    0    1    1    1    0\n",
      "    0    1    0    0    0    0    0    1    1    0    0    1    0    1\n",
      "    1    1    0    1    0    0    1    0    0    0    0    1    1    0\n",
      "    1    1    1    0    0    0    1    1    1    1    1    0    1    1\n",
      "    1    1    0    0    1    0    0    0    2] -1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    "    jobs=np.copy(jobs),\n",
    ")\n",
    "obs = env.reset()\n",
    "print(obs.shape)\n",
    "\n",
    "action = env.action_space.sample()\n",
    "print(\"Action:\\n\", action)\n",
    "obs, reward, done, info = env.step(action)\n",
    "print(\"Step:\\n\", obs, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    "    jobs=np.copy(jobs),\n",
    ")\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    "    jobs=np.copy(jobs),\n",
    ")\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    "    jobs=np.copy(jobs),\n",
    ")\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.10.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "1 10\n",
      "2 0\n",
      "3 9\n",
      "4 8\n",
      "5 2\n",
      "6 1\n",
      "7 8\n",
      "8 2\n",
      "9 9\n",
      "10 2\n",
      "11 6\n",
      "12 3\n",
      "13 6\n",
      "14 4\n",
      "15 5\n",
      "16 2\n",
      "17 7\n",
      "18 0\n",
      "19 5\n",
      "20 8\n",
      "21 7\n",
      "22 5\n",
      "23 7\n",
      "24 3\n",
      "25 3\n",
      "26 4\n",
      "27 2\n",
      "28 1\n",
      "29 7\n",
      "30 1\n",
      "31 2\n",
      "32 3\n",
      "33 3\n",
      "34 9\n",
      "35 1\n",
      "36 7\n",
      "37 7\n",
      "38 4\n",
      "39 5\n",
      "40 8\n",
      "41 1\n",
      "42 0\n",
      "43 10\n",
      "44 9\n",
      "45 9\n",
      "46 0\n",
      "47 6\n",
      "48 6\n",
      "49 3\n",
      "50 2\n",
      "51 4\n",
      "Episode finished after 52 timesteps\n"
     ]
    }
   ],
   "source": [
    "from res_mgmt.envs.generator import generate_jobs\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "import numpy as np\n",
    "\n",
    "num_resource_type = 10\n",
    "time_size = 5\n",
    "resource_size = 10\n",
    "\n",
    "jobs = generate_jobs(num_resource_type, time_size, resource_size)\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=10,\n",
    "    max_num_job=10**3,\n",
    "    jobs=np.copy(jobs),\n",
    ")\n",
    "\n",
    "observation = env.reset()\n",
    "t = 0\n",
    "while True:\n",
    "    t += 1\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(t, action)\n",
    "    env.my_render(f\"render/{t}.png\")\n",
    "    if done or t > 50:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2076.,  7203., 20071., 40748., 57475., 57639., 40648., 20056.,\n",
       "         7171.,  2005.]),\n",
       " array([ 1. ,  1.9,  2.8,  3.7,  4.6,  5.5,  6.4,  7.3,  8.2,  9.1, 10. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from res_mgmt.generator.generator import generate_jobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jobs = generate_jobs(10, 50, 10)\n",
    "jobs = jobs.reshape(10000, 50, 10)\n",
    "def duration(image):\n",
    "    return np.max(np.where(image == True), axis=1)[0] + 1\n",
    "def max_req(image):\n",
    "    return np.max(np.where(image == True), axis=1)[1] + 1\n",
    "def reqs(image):\n",
    "    t = np.where(image == True)\n",
    "    if t[0].size == 0:\n",
    "        return 0\n",
    "    return np.max(np.where(image == True)) + 1\n",
    "durstions = [duration(jobs[i]) for i in range(jobs.shape[0])]\n",
    "max_reqs = [max_req(jobs[i]) for i in range(jobs.shape[0])]\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3)\n",
    "ax0.hist(durstions)\n",
    "ax1.hist(max_reqs)\n",
    "jobs = jobs.reshape(500000, 10)\n",
    "reqss = [reqs(jobs[i]) for i in range(jobs.shape[0]) if reqs(jobs[i]) != 0]\n",
    "ax2.hist(reqss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_res_mgmt_tensorboard/A2C_2\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 3         |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.02     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -1.04e+03 |\n",
      "|    value_loss         | 2.84e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -599     |\n",
      "|    value_loss         | 1.67e+05 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "num_resource_type = 10\n",
    "time_size = 5\n",
    "resource_size = 10\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=10,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "# Parallel environments\n",
    "# env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    gamma=1,\n",
    "    tensorboard_log=\"./a2c_res_mgmt_tensorboard/\",\n",
    ")\n",
    "# model.learn(total_timesteps=25000)\n",
    "model.learn(total_timesteps=1000)\n",
    "model.save(\"a2c_res_mgmt\")\n",
    "\n",
    "del model  # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0\n",
      "100 10 -233.23333333333332\n",
      "200 1 0\n",
      "300 3 -224.10000000000002\n",
      "400 4 0\n",
      "500 3 -215.20000000000002\n",
      "600 4 0\n",
      "700 3 -205.20000000000002\n",
      "800 10 -200.20000000000002\n",
      "900 4 -195.41666666666669\n",
      "1000 10 0\n",
      "1100 10 -185.98333333333335\n",
      "1200 4 -181.18333333333334\n",
      "1300 6 0\n",
      "1400 3 -171.55\n",
      "1500 1 0\n",
      "1600 3 -162.0666666666667\n",
      "1700 6 0\n",
      "1800 3 -153.33333333333334\n",
      "1900 4 0\n",
      "2000 9 0\n",
      "2100 6 -138.56666666666666\n",
      "2200 10 0\n",
      "2300 0 -128.6\n",
      "2400 0 -124.35\n",
      "2500 3 0\n",
      "2600 3 -114.46666666666667\n",
      "2700 4 -109.63333333333334\n",
      "2800 3 -105.13333333333333\n",
      "2900 10 -100.93333333333334\n",
      "3000 6 -95.9\n",
      "3100 4 0\n",
      "3200 4 -86.7\n",
      "3300 6 -82.2\n",
      "3400 4 -77.8\n",
      "3500 10 -72.48333333333332\n",
      "3600 2 -67.73333333333332\n",
      "3700 10 -63.28333333333333\n",
      "3800 3 0\n",
      "3900 3 0\n",
      "4000 4 -48.78333333333333\n",
      "4100 3 -44.1\n",
      "4200 3 -39.75\n",
      "4300 9 -34.916666666666664\n",
      "4400 3 0\n",
      "4500 3 -25.1\n",
      "4600 3 -20.4\n",
      "4700 3 0\n",
      "4800 10 -10.683333333333332\n",
      "4900 0 -6.683333333333334\n",
      "5000 5 0\n",
      "Episode finished after 5091 timesteps\n"
     ]
    }
   ],
   "source": [
    "model = A2C.load(\"a2c_res_mgmt\")\n",
    "\n",
    "obs = env.reset()\n",
    "t = 0\n",
    "max_iteration = 10 ** 5\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if t % 100 == 0:\n",
    "        print(t, action, reward)\n",
    "        env.my_render(f\"render/{t}.png\")\n",
    "    if done or t > max_iteration:\n",
    "        print(\"Episode finished after {} timesteps\".format(t))\n",
    "        break\n",
    "    t += 1\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Development\\dissertation\\resource-management-env\\experiment.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/dissertation/resource-management-env/experiment.ipynb#ch0000009?line=30'>31</a>\u001b[0m \u001b[39m# episode = 10\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/dissertation/resource-management-env/experiment.ipynb#ch0000009?line=31'>32</a>\u001b[0m episode \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Development/dissertation/resource-management-env/experiment.ipynb#ch0000009?line=33'>34</a>\u001b[0m mean_reward, std_reward \u001b[39m=\u001b[39m evaluate_policy(model, env, n_eval_episodes\u001b[39m=\u001b[39;49mepisode, deterministic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/dissertation/resource-management-env/experiment.ipynb#ch0000009?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean_reward=\u001b[39m\u001b[39m{\u001b[39;00mmean_reward\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m +/- \u001b[39m\u001b[39m{\u001b[39;00mstd_reward\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/dissertation/resource-management-env/experiment.ipynb#ch0000009?line=36'>37</a>\u001b[0m \u001b[39m# model.learn(total_timesteps=25000)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:85\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/evaluation.py?line=82'>83</a>\u001b[0m states \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/evaluation.py?line=83'>84</a>\u001b[0m \u001b[39mwhile\u001b[39;00m (episode_counts \u001b[39m<\u001b[39m episode_count_targets)\u001b[39m.\u001b[39many():\n\u001b[1;32m---> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/evaluation.py?line=84'>85</a>\u001b[0m     actions, states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(observations, state\u001b[39m=\u001b[39;49mstates, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[0;32m     <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/evaluation.py?line=85'>86</a>\u001b[0m     observations, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(actions)\n\u001b[0;32m     <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/evaluation.py?line=86'>87</a>\u001b[0m     current_rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rewards\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:540\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, mask, deterministic)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=522'>523</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=523'>524</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=524'>525</a>\u001b[0m     observation: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=527'>528</a>\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=528'>529</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[np\u001b[39m.\u001b[39mndarray]]:\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=529'>530</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=530'>531</a>\u001b[0m \u001b[39m    Get the model's action(s) from an observation\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=531'>532</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=537'>538</a>\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=538'>539</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/base_class.py?line=539'>540</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, mask, deterministic)\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\policies.py:326\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, mask, deterministic)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=322'>323</a>\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=324'>325</a>\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=325'>326</a>\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=326'>327</a>\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=327'>328</a>\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\policies.py:647\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=638'>639</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=639'>640</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=640'>641</a>\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=641'>642</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=644'>645</a>\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=645'>646</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=646'>647</a>\u001b[0m     latent_pi, _, latent_sde \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_latent(observation)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=647'>648</a>\u001b[0m     distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_action_dist_from_latent(latent_pi, latent_sde)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=648'>649</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m distribution\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\policies.py:604\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_latent\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=594'>595</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=595'>596</a>\u001b[0m \u001b[39mGet the latent code (i.e., activations of the last layer of each network)\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=596'>597</a>\u001b[0m \u001b[39mfor the different networks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=600'>601</a>\u001b[0m \u001b[39m    for the actor, the value function and for gSDE function\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=601'>602</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=602'>603</a>\u001b[0m \u001b[39m# Preprocess the observation if needed\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=603'>604</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(obs)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=604'>605</a>\u001b[0m latent_pi, latent_vf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor(features)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=606'>607</a>\u001b[0m \u001b[39m# Features for sde\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\policies.py:127\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=119'>120</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=120'>121</a>\u001b[0m \u001b[39mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=121'>122</a>\u001b[0m \n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=122'>123</a>\u001b[0m \u001b[39m:param obs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=123'>124</a>\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=124'>125</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=125'>126</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mNo features extractor was set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=126'>127</a>\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space, normalize_images\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_images)\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/policies.py?line=127'>128</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor(preprocessed_obs)\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\preprocessing.py:113\u001b[0m, in \u001b[0;36mpreprocess_obs\u001b[1;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mone_hot(obs\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39mobservation_space\u001b[39m.\u001b[39mn)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=109'>110</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, spaces\u001b[39m.\u001b[39mMultiDiscrete):\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=110'>111</a>\u001b[0m     \u001b[39m# Tensor concatenation of one hot encodings of each Categorical sub-space\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=111'>112</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m th\u001b[39m.\u001b[39mcat(\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=112'>113</a>\u001b[0m         [\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=113'>114</a>\u001b[0m             F\u001b[39m.\u001b[39mone_hot(obs_\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(observation_space\u001b[39m.\u001b[39mnvec[idx]))\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=114'>115</a>\u001b[0m             \u001b[39mfor\u001b[39;00m idx, obs_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(th\u001b[39m.\u001b[39msplit(obs\u001b[39m.\u001b[39mlong(), \u001b[39m1\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=115'>116</a>\u001b[0m         ],\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=116'>117</a>\u001b[0m         dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=117'>118</a>\u001b[0m     )\u001b[39m.\u001b[39mview(obs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39msum\u001b[39m(observation_space\u001b[39m.\u001b[39mnvec))\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=119'>120</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, spaces\u001b[39m.\u001b[39mMultiBinary):\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=120'>121</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obs\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[1;32mD:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\stable_baselines3\\common\\preprocessing.py:114\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mone_hot(obs\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39mobservation_space\u001b[39m.\u001b[39mn)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=109'>110</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, spaces\u001b[39m.\u001b[39mMultiDiscrete):\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=110'>111</a>\u001b[0m     \u001b[39m# Tensor concatenation of one hot encodings of each Categorical sub-space\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=111'>112</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m th\u001b[39m.\u001b[39mcat(\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=112'>113</a>\u001b[0m         [\n\u001b[1;32m--> <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=113'>114</a>\u001b[0m             F\u001b[39m.\u001b[39;49mone_hot(obs_\u001b[39m.\u001b[39;49mlong(), num_classes\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(observation_space\u001b[39m.\u001b[39;49mnvec[idx]))\u001b[39m.\u001b[39;49mfloat()\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=114'>115</a>\u001b[0m             \u001b[39mfor\u001b[39;00m idx, obs_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(th\u001b[39m.\u001b[39msplit(obs\u001b[39m.\u001b[39mlong(), \u001b[39m1\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=115'>116</a>\u001b[0m         ],\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=116'>117</a>\u001b[0m         dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=117'>118</a>\u001b[0m     )\u001b[39m.\u001b[39mview(obs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39msum\u001b[39m(observation_space\u001b[39m.\u001b[39mnvec))\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=119'>120</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, spaces\u001b[39m.\u001b[39mMultiBinary):\n\u001b[0;32m    <a href='file:///d%3A/Programs/Miniconda3/envs/res-mgmt-rl-cuda-dev/lib/site-packages/stable_baselines3/common/preprocessing.py?line=120'>121</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obs\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "num_resource_type = 3\n",
    "time_size = 5\n",
    "resource_size = 5\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=10,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "# Parallel environments\n",
    "# env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    gamma=1,\n",
    "    tensorboard_log=\"./a2c_res_mgmt_tensorboard/\",\n",
    ")\n",
    "\n",
    "# episode = 10\n",
    "episode = 2\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episode, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n",
    "\n",
    "# model.learn(total_timesteps=25000)\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episode, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n",
    "\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01aaff945cac5d88624c70989d7ef7df0a174617aa94a0c3a7bd3351af0aef77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('resmgmt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
