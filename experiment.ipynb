{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41,)\n",
      "Action:\n",
      " 0\n",
      "Step:\n",
      " [  3   3   3   3   3   3   3   3   3   3   2   1   1   0   0   2   2   2\n",
      "   2   0   3   2   2   0   0   2   2   3   1   3   2   2   0   0   0   3\n",
      "   3   2   0   0 997] -301.56666666666666 False {}\n"
     ]
    }
   ],
   "source": [
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "obs = env.reset()\n",
    "print(obs.shape)\n",
    "\n",
    "action = env.action_space.sample()\n",
    "print(\"Action:\\n\", action)\n",
    "obs, reward, done, info = env.step(action)\n",
    "print(\"Step:\\n\", obs, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Miniconda3\\envs\\res-mgmt-rl-cuda-dev\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1f9b88dc708>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=2,\n",
    "    resource_size=3,\n",
    "    time_size=5,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 6\n",
      "3 2\n",
      "4 7\n",
      "5 6\n",
      "6 4\n",
      "7 0\n",
      "8 9\n",
      "9 9\n",
      "10 9\n",
      "11 2\n",
      "12 6\n",
      "13 1\n",
      "14 2\n",
      "15 5\n",
      "16 2\n",
      "17 6\n",
      "18 3\n",
      "19 0\n",
      "20 0\n",
      "21 8\n",
      "22 3\n",
      "23 2\n",
      "24 2\n",
      "25 8\n",
      "26 7\n",
      "27 5\n",
      "28 4\n",
      "29 9\n",
      "30 10\n",
      "31 4\n",
      "32 3\n",
      "33 9\n",
      "34 7\n",
      "35 5\n",
      "36 0\n",
      "37 8\n",
      "38 5\n",
      "39 6\n",
      "40 3\n",
      "41 1\n",
      "42 0\n",
      "43 3\n",
      "44 3\n",
      "45 10\n",
      "46 4\n",
      "47 8\n",
      "48 2\n",
      "49 10\n",
      "50 1\n",
      "51 10\n",
      "Episode finished after 52 timesteps\n"
     ]
    }
   ],
   "source": [
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "import numpy as np\n",
    "\n",
    "num_resource_type = 10\n",
    "time_size = 5\n",
    "resource_size = 10\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=10,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "observation = env.reset()\n",
    "t = 0\n",
    "while True:\n",
    "    t += 1\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(t, action)\n",
    "    env.my_render(f\"render/{t}.png\")\n",
    "    if done or t > 50:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2013.,  6961., 20262., 40522., 57928., 58080., 40745., 20445.,\n",
       "         7277.,  2073.]),\n",
       " array([ 1. ,  1.9,  2.8,  3.7,  4.6,  5.5,  6.4,  7.3,  8.2,  9.1, 10. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from res_mgmt.envs.generator import generate_jobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jobs = generate_jobs(10, 50, 10)\n",
    "jobs = jobs.reshape(10000, 50, 10)\n",
    "def duration(image):\n",
    "    return np.max(np.where(image == True), axis=1)[0] + 1\n",
    "def max_req(image):\n",
    "    return np.max(np.where(image == True), axis=1)[1] + 1\n",
    "def reqs(image):\n",
    "    t = np.where(image == True)\n",
    "    if t[0].size == 0:\n",
    "        return 0\n",
    "    return np.max(np.where(image == True)) + 1\n",
    "durstions = [duration(jobs[i]) for i in range(jobs.shape[0])]\n",
    "max_reqs = [max_req(jobs[i]) for i in range(jobs.shape[0])]\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3)\n",
    "ax0.hist(durstions)\n",
    "ax1.hist(max_reqs)\n",
    "jobs = jobs.reshape(500000, 10)\n",
    "reqss = [reqs(jobs[i]) for i in range(jobs.shape[0]) if reqs(jobs[i]) != 0]\n",
    "ax2.hist(reqss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_res_mgmt_tensorboard/A2C_6\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 256      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 1.22e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -518     |\n",
      "|    value_loss         | 4.45e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 269      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.961   |\n",
      "|    explained_variance | 8.94e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -724     |\n",
      "|    value_loss         | 3.73e+05 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "num_resource_type = 2\n",
    "time_size = 5\n",
    "resource_size = 3\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "# Parallel environments\n",
    "# env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    gamma=1,\n",
    "    tensorboard_log=\"./a2c_res_mgmt_tensorboard/\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "# model.learn(total_timesteps=25000)\n",
    "model.learn(total_timesteps=1000)\n",
    "model.save(\"a2c_res_mgmt\")\n",
    "\n",
    "del model  # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_res_mgmt_tensorboard/A2C_7\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 2.5e-06  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -711     |\n",
      "|    value_loss         | 5.64e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.942   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -275     |\n",
      "|    value_loss         | 3.73e+05 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "num_resource_type = 2\n",
    "time_size = 5\n",
    "resource_size = 3\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10**3,\n",
    ")\n",
    "\n",
    "# Parallel environments\n",
    "# env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    gamma=1,\n",
    "    tensorboard_log=\"./a2c_res_mgmt_tensorboard/\",\n",
    ")\n",
    "# model.learn(total_timesteps=25000)\n",
    "model.learn(total_timesteps=1000)\n",
    "model.save(\"a2c_res_mgmt\")\n",
    "\n",
    "del model  # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 0\n",
      "1000 5 -191.91666666666666\n",
      "2000 6 0\n",
      "3000 5 0\n",
      "4000 7 -49.150000000000006\n",
      "5000 7 0\n",
      "Episode finished after 5065 timesteps\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C.load(\"a2c_res_mgmt\")\n",
    "\n",
    "obs = env.reset()\n",
    "t = 0\n",
    "max_iteration = 10 ** 5\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if t % 1000 == 0:\n",
    "        print(t, action, reward)\n",
    "        env.my_render(f\"render/{t}.png\")\n",
    "    if done or t > max_iteration:\n",
    "        print(\"Episode finished after {} timesteps\".format(t))\n",
    "        break\n",
    "    t += 1\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv\n",
    "\n",
    "num_resource_type = 2\n",
    "time_size = 5\n",
    "resource_size = 3\n",
    "\n",
    "env = ResMgmtEnv(\n",
    "    num_resource_type=num_resource_type,\n",
    "    time_size=time_size,\n",
    "    resource_size=resource_size,\n",
    "    num_job_slot=3,\n",
    "    max_num_job=10,\n",
    ")\n",
    "\n",
    "# Parallel environments\n",
    "# env = make_vec_env(\"CartPole-v1\", n_envs=4)\n",
    "\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    gamma=1,\n",
    "    tensorboard_log=\"./a2c_res_mgmt_tensorboard/\",\n",
    ")\n",
    "\n",
    "# episode = 10\n",
    "episode = 2\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episode, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n",
    "\n",
    "# model.learn(total_timesteps=25000)\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episode, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "jobs = np.array(\n",
    "    [[[[True,  True, False],\n",
    "        [True, False,  True],\n",
    "        [True, False,  True],\n",
    "        [False, False,  True],\n",
    "        [False,  True,  True]],\n",
    "\n",
    "      [[False, False,  True],\n",
    "        [True,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [False, False, False],\n",
    "        [False,  True, False]]],\n",
    "\n",
    "\n",
    "      [[[False, False,  True],\n",
    "        [False,  True, False],\n",
    "        [True,  True,  True],\n",
    "        [False, False,  True],\n",
    "        [False, False, False]],\n",
    "\n",
    "      [[False, False,  True],\n",
    "        [True, False, False],\n",
    "        [True, False,  True],\n",
    "        [True,  True, False],\n",
    "        [True, False, False]]],\n",
    "\n",
    "\n",
    "      [[[True, False, False],\n",
    "        [False, False,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True, False],\n",
    "        [False, False,  True]],\n",
    "\n",
    "      [[True,  True,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True,  True],\n",
    "        [False, False,  True],\n",
    "        [False, False, False]]],\n",
    "\n",
    "\n",
    "      [[[False, False,  True],\n",
    "        [True,  True, False],\n",
    "        [False,  True, False],\n",
    "        [False,  True,  True],\n",
    "        [True, False, False]],\n",
    "\n",
    "      [[False,  True, False],\n",
    "        [False,  True, False],\n",
    "        [True,  True, False],\n",
    "        [False, False, False],\n",
    "        [True, False,  True]]],\n",
    "\n",
    "\n",
    "      [[[True, False,  True],\n",
    "        [False,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [True, False, False],\n",
    "        [True, False,  True]],\n",
    "\n",
    "      [[True,  True, False],\n",
    "        [False,  True,  True],\n",
    "        [False,  True,  True],\n",
    "        [True, False,  True],\n",
    "        [True,  True,  True]]]]\n",
    ")\n",
    "from res_mgmt.envs.res_mgmt_env import ResMgmtEnv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01aaff945cac5d88624c70989d7ef7df0a174617aa94a0c3a7bd3351af0aef77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('resmgmt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
